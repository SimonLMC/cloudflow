{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4827f877-09f7-46b4-84d5-ae4e289ef4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "No model was supplied, defaulted to t5-base and revision 686f1db (https://huggingface.co/t5-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/home/quinten/Utilisateurs/slemouellic/.local/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5_fast.py:156: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "No model was supplied, defaulted to google/vit-base-patch16-224 and revision 5dca96d (https://huggingface.co/google/vit-base-patch16-224).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import os\n",
    "import importlib\n",
    "from transformers import pipeline\n",
    "\n",
    "summarization_model = pipeline(\"summarization\")\n",
    "sentiment_model = pipeline(\"sentiment-analysis\")\n",
    "translation_model = pipeline('translation_en_to_fr')\n",
    "image_classification = pipeline(\"image-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb79f838-a3ea-442d-be25-dc7d19c30030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import download_file\n",
    "\n",
    "def predict_to_save(sentiment_model,summarization_model, translation_model,image_classification,input_type, data = None,min_length = 0, max_length = 150):\n",
    "    \"\"\"\n",
    "    make and combine the prediction of all the differents models on the differents scoring tables\n",
    "\n",
    "    params_scoring dictionnary: dictionnary that contain all the scoring tables on which models will...\n",
    "    ... make predictions. It have to be a dictionnary as the predict function of mlflow only take a single argument.\n",
    "\n",
    "    Return Pandas dataframe with all the fraud risk score (and few others informations) on the remise batch\n",
    "    Return interpretation_remises pandas dataframe with the interpretation for the remises model\n",
    "    Return interpretation_client pandas dataframe with the interpretation for the clients models\n",
    "    \"\"\"\n",
    "    \n",
    "    if input_type == \"sentiment\":\n",
    "        return sentiment_model(data)\n",
    "    elif input_type == \"translation\":\n",
    "        return translation_model(data)\n",
    "    elif input_type == \"image\":\n",
    "        image = download_file.download_image(data)\n",
    "        return image_classification(image)\n",
    "    elif input_type == \"summarization\":\n",
    "\n",
    "        if data is None:\n",
    "            data = download_file.download_story()\n",
    "\n",
    "        dict_result = summarization_model(data, min_length, max_length)[0]\n",
    "        dict_result[\"input_text\"] = data\n",
    "        return dict_result\n",
    "\n",
    "    return \"mauvais type selectionnÃ©\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81bb3cc2-eff5-476c-b54d-c13ea2b9ca11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-12 16:10:49,727.727 INFO save: Artifact path --> /home/quinten/Projets/BPRI - Fraude/test_package_mlflow/mlruns/quinten_test/226dc785fb264a03b097037756fccc64\n",
      "2023-02-12 16:10:49,728.728 DEBUG get_all_subfolders: /home/quinten/Utilisateurs/slemouellic/MLFLOW_save --> Subfolder analysis\n",
      "2023-02-12 16:10:49,730.730 DEBUG get_all_subfolders: /home/quinten/Utilisateurs/slemouellic/MLFLOW_save/sub_folder --> Subfolder analysis\n",
      "2023-02-12 16:10:49,733.733 DEBUG get_all_subfolders: /home/quinten/Utilisateurs/slemouellic/MLFLOW_save/sub_folder/subsub_folder --> Subfolder analysis\n",
      "2023-02-12 16:10:49,735.735 DEBUG get_all_subfolders: /home/quinten/Utilisateurs/slemouellic/MLFLOW_save/logs --> Subfolder analysis\n",
      "2023-02-12 16:10:49,742.742 DEBUG register_all_function_by_value: download_file --> Analysis\n",
      "2023-02-12 16:10:49,743.743 DEBUG register_all_function_by_value: <module 'download_file' from '/home/quinten/Utilisateurs/slemouellic/MLFLOW_save/download_file.py'> --> Enregistrement\n",
      "2023-02-12 16:10:49,744.744 DEBUG register_all_function_by_value: no_import --> Analysis\n",
      "2023-02-12 16:10:49,746.746 DEBUG register_all_function_by_value: <module 'no_import' from '/home/quinten/Utilisateurs/slemouellic/MLFLOW_save/no_import.py'> --> Enregistrement\n",
      "2023-02-12 16:10:49,747.747 DEBUG register_all_function_by_value: to_import --> Analysis\n",
      "2023-02-12 16:10:49,749.749 DEBUG register_all_function_by_value: <module 'to_import' from '/home/quinten/Utilisateurs/slemouellic/MLFLOW_save/to_import.py'> --> Enregistrement\n",
      "2023-02-12 16:10:49,750.750 DEBUG register_all_function_by_value: utils --> Analysis\n",
      "2023-02-12 16:10:49,752.752 DEBUG register_all_function_by_value: <module 'utils' from '/home/quinten/Utilisateurs/slemouellic/MLFLOW_save/utils.py'> --> Enregistrement\n",
      "2023-02-12 16:10:49,755.755 DEBUG register_all_function_by_value: test_import --> Analysis\n",
      "2023-02-12 16:10:49,758.758 DEBUG register_all_function_by_value: <module 'sub_folder.test_import' from '/home/quinten/Utilisateurs/slemouellic/MLFLOW_save/sub_folder/test_import.py'> --> Enregistrement\n",
      "2023-02-12 16:10:49,760.760 DEBUG register_all_function_by_value: is_sub --> Analysis\n",
      "2023-02-12 16:10:49,762.762 DEBUG register_all_function_by_value: <module 'sub_folder.subsub_folder.is_sub' from '/home/quinten/Utilisateurs/slemouellic/MLFLOW_save/sub_folder/subsub_folder/is_sub.py'> --> Enregistrement\n",
      "2023-02-12 16:10:49,766.766 DEBUG register_all_function_by_value: test_import --> Analysis\n",
      "2023-02-12 16:10:49,768.768 DEBUG register_all_function_by_value: <module 'sub_folder.subsub_folder.sub_folder.test_import' from '/home/quinten/Utilisateurs/slemouellic/MLFLOW_save/sub_folder/test_import.py'> --> Enregistrement\n",
      "2023-02-12 16:10:49,771.771 DEBUG register_all_function_by_value: is_sub --> Analysis\n",
      "2023-02-12 16:10:49,772.772 DEBUG register_all_function_by_value: <module 'sub_folder.subsub_folder.sub_folder.subsub_folder.is_sub' from '/home/quinten/Utilisateurs/slemouellic/MLFLOW_save/sub_folder/subsub_folder/is_sub.py'> --> Enregistrement\n",
      "2023-02-12 16:10:49,774.774 DEBUG pickle_artifacts: pickle function--> __predict__\n",
      "2023-02-12 16:10:49,775.775 DEBUG pickle_artifacts: pickle function path --> /home/quinten/Projets/BPRI - Fraude/test_package_mlflow/mlruns/quinten_test/226dc785fb264a03b097037756fccc64/__predict__.pkl\n",
      "2023-02-12 16:10:49,821.821 DEBUG pickle_artifacts: pickle function DONE\n",
      "2023-02-12 16:10:49,822.822 DEBUG pickle_artifacts: model --> summarization_model\n",
      "2023-02-12 16:10:49,823.823 DEBUG pickle_artifacts: pickle model --> summarization_model\n",
      "2023-02-12 16:10:49,824.824 DEBUG pickle_artifacts: pickle model path --> /home/quinten/Projets/BPRI - Fraude/test_package_mlflow/mlruns/quinten_test/226dc785fb264a03b097037756fccc64/summarization_model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN ID :  226dc785fb264a03b097037756fccc64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-12 16:11:19,978.978 DEBUG pickle_artifacts: pickle model DONE\n",
      "2023-02-12 16:11:19,979.979 DEBUG pickle_artifacts: model --> image_classification\n",
      "2023-02-12 16:11:19,980.980 DEBUG pickle_artifacts: pickle model --> image_classification\n",
      "2023-02-12 16:11:19,981.981 DEBUG pickle_artifacts: pickle model path --> /home/quinten/Projets/BPRI - Fraude/test_package_mlflow/mlruns/quinten_test/226dc785fb264a03b097037756fccc64/image_classification.pkl\n",
      "2023-02-12 16:11:25,013.013 DEBUG pickle_artifacts: pickle model DONE\n",
      "2023-02-12 16:11:25,014.014 DEBUG pickle_artifacts: model --> translation_model\n",
      "2023-02-12 16:11:25,016.016 DEBUG pickle_artifacts: pickle model --> translation_model\n",
      "2023-02-12 16:11:25,017.017 DEBUG pickle_artifacts: pickle model path --> /home/quinten/Projets/BPRI - Fraude/test_package_mlflow/mlruns/quinten_test/226dc785fb264a03b097037756fccc64/translation_model.pkl\n",
      "2023-02-12 16:11:46,879.879 DEBUG pickle_artifacts: pickle model DONE\n",
      "2023-02-12 16:11:46,881.881 DEBUG pickle_artifacts: model --> sentiment_model\n",
      "2023-02-12 16:11:46,882.882 DEBUG pickle_artifacts: pickle model --> sentiment_model\n",
      "2023-02-12 16:11:46,883.883 DEBUG pickle_artifacts: pickle model path --> /home/quinten/Projets/BPRI - Fraude/test_package_mlflow/mlruns/quinten_test/226dc785fb264a03b097037756fccc64/sentiment_model.pkl\n",
      "2023-02-12 16:11:51,258.258 DEBUG pickle_artifacts: pickle model DONE\n",
      "2023-02-12 16:11:51,260.260 DEBUG save: {'__predict__': '/home/quinten/Projets/BPRI - Fraude/test_package_mlflow/mlruns/quinten_test/226dc785fb264a03b097037756fccc64/__predict__.pkl', 'summarization_model': '/home/quinten/Projets/BPRI - Fraude/test_package_mlflow/mlruns/quinten_test/226dc785fb264a03b097037756fccc64/summarization_model.pkl', 'image_classification': '/home/quinten/Projets/BPRI - Fraude/test_package_mlflow/mlruns/quinten_test/226dc785fb264a03b097037756fccc64/image_classification.pkl', 'translation_model': '/home/quinten/Projets/BPRI - Fraude/test_package_mlflow/mlruns/quinten_test/226dc785fb264a03b097037756fccc64/translation_model.pkl', 'sentiment_model': '/home/quinten/Projets/BPRI - Fraude/test_package_mlflow/mlruns/quinten_test/226dc785fb264a03b097037756fccc64/sentiment_model.pkl'}\n",
      "/home/quinten/Utilisateurs/slemouellic/.local/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "2023-02-12 16:13:22,864.864 INFO mkpath: creating /home/quinten/Projets/BPRI - Fraude/test_package_mlflow/mlruns/quinten_test/226dc785fb264a03b097037756fccc64/artifacts/Model/artifacts\n",
      "2023-02-12 16:14:02,205.205 DEBUG save: Artifact list --> {'__predict__': '/home/quinten/Projets/BPRI - Fraude/test_package_mlflow/mlruns/quinten_test/226dc785fb264a03b097037756fccc64/__predict__.pkl', 'summarization_model': '/home/quinten/Projets/BPRI - Fraude/test_package_mlflow/mlruns/quinten_test/226dc785fb264a03b097037756fccc64/summarization_model.pkl', 'image_classification': '/home/quinten/Projets/BPRI - Fraude/test_package_mlflow/mlruns/quinten_test/226dc785fb264a03b097037756fccc64/image_classification.pkl', 'translation_model': '/home/quinten/Projets/BPRI - Fraude/test_package_mlflow/mlruns/quinten_test/226dc785fb264a03b097037756fccc64/translation_model.pkl', 'sentiment_model': '/home/quinten/Projets/BPRI - Fraude/test_package_mlflow/mlruns/quinten_test/226dc785fb264a03b097037756fccc64/sentiment_model.pkl'}\n"
     ]
    }
   ],
   "source": [
    "import cloudflow\n",
    "importlib.reload(cloudflow)\n",
    "\n",
    "tracking_uri =\"/home/quinten/Projets/BPRI - Fraude/test_package_mlflow\"\n",
    "experiment_id = \"quinten_test\" \n",
    "\n",
    "cloudflow.prepare_env(tracking_uri,experiment_id)\n",
    "\n",
    "with mlflow.start_run(experiment_id = experiment_id) as run:\n",
    "    \n",
    "    print(\"RUN ID : \", run.info.run_id)\n",
    "    \n",
    "    mlflow.log_metric('test_metrics', 0.99)\n",
    "\n",
    "    model = cloudflow.cloudflow_model(\"DEBUG\")        \n",
    "    model.save(tracking_uri    = tracking_uri,\n",
    "               experiment_id = experiment_id,\n",
    "               run_id = run.info.run_id, \n",
    "               predict_function = predict_to_save, \n",
    "               models = {\"summarization_model\"  : summarization_model, \n",
    "                         \"image_classification\" : image_classification,\n",
    "                         \"translation_model\"    : translation_model,\n",
    "                         \"sentiment_model\"      : sentiment_model})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a03fc68-9ee7-479f-be4b-2ce4f70831c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dae73d-8151-4b29-bda7-83c46a379180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
