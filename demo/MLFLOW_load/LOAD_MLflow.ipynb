{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "861387e4-2e69-4fa5-b94f-d747c6f47278",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-12 16:15:44,377.377 DEBUG load_context: loading __predict__ --> START\n",
      "2023-02-12 16:15:44,380.380 DEBUG load_context: loading __predict__ --> DONE\n",
      "2023-02-12 16:15:44,381.381 DEBUG load_context: loading image_classification --> START\n",
      "2023-02-12 16:15:51,475.475 DEBUG <module>: Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
      "2023-02-12 16:15:52,553.553 DEBUG <module>: Creating converter from 7 to 5\n",
      "2023-02-12 16:15:52,556.556 DEBUG <module>: Creating converter from 5 to 7\n",
      "2023-02-12 16:15:52,557.557 DEBUG <module>: Creating converter from 7 to 5\n",
      "2023-02-12 16:15:52,558.558 DEBUG <module>: Creating converter from 5 to 7\n",
      "2023-02-12 16:16:15,157.157 DEBUG load_context: loading image_classification --> DONE\n",
      "2023-02-12 16:16:15,159.159 DEBUG load_context: loading sentiment_model --> START\n",
      "2023-02-12 16:16:16,350.350 DEBUG load_context: loading sentiment_model --> DONE\n",
      "2023-02-12 16:16:16,351.351 DEBUG load_context: loading summarization_model --> START\n",
      "2023-02-12 16:16:20,222.222 DEBUG load_context: loading summarization_model --> DONE\n",
      "2023-02-12 16:16:20,223.223 DEBUG load_context: loading translation_model --> START\n",
      "2023-02-12 16:16:21,180.180 DEBUG load_context: loading translation_model --> DONE\n"
     ]
    }
   ],
   "source": [
    "import cloudflow\n",
    "\n",
    "loaded_model = cloudflow.cloudflow_model(\"DEBUG\")\n",
    "\n",
    "loaded_model.load_model(tracking_uri = \"/home/quinten/Projets/BPRI - Fraude/test_package_mlflow\",\n",
    "                        experiment_id = \"quinten_test\",\n",
    "                        model_id    = \"#your run id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9998a071-7682-414a-8b5e-96cd14fe6c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-12 16:16:32,304.304 DEBUG predict: Default arg --> min_length\n",
      "2023-02-12 16:16:32,306.306 DEBUG predict: Default Value --> 0\n",
      "2023-02-12 16:16:32,308.308 DEBUG predict: Default arg --> max_length\n",
      "2023-02-12 16:16:32,309.309 DEBUG predict: Default Value --> 150\n",
      "2023-02-12 16:16:32,310.310 DEBUG predict: Input Arg --> sentiment_model\n",
      "2023-02-12 16:16:32,311.311 DEBUG predict: Input Value --> <transformers.pipelines.text_classification.TextClassificationPipeline object at 0x7f612b335040>\n",
      "2023-02-12 16:16:32,312.312 DEBUG predict: Input Arg --> summarization_model\n",
      "2023-02-12 16:16:32,313.313 DEBUG predict: Input Value --> <transformers.pipelines.text2text_generation.SummarizationPipeline object at 0x7f6128f01100>\n",
      "2023-02-12 16:16:32,314.314 DEBUG predict: Input Arg --> translation_model\n",
      "2023-02-12 16:16:32,315.315 DEBUG predict: Input Value --> <transformers.pipelines.text2text_generation.TranslationPipeline object at 0x7f611b63a310>\n",
      "2023-02-12 16:16:32,316.316 DEBUG predict: Input Arg --> image_classification\n",
      "2023-02-12 16:16:32,317.317 DEBUG predict: Input Value --> <transformers.pipelines.image_classification.ImageClassificationPipeline object at 0x7f6254128880>\n",
      "2023-02-12 16:16:32,319.319 DEBUG predict: Input Arg --> input_type\n",
      "2023-02-12 16:16:32,320.320 DEBUG predict: Input Value --> image\n",
      "2023-02-12 16:16:32,320.320 DEBUG predict: Input Arg --> data\n",
      "2023-02-12 16:16:32,321.321 DEBUG predict: Input Value --> https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample.png\n",
      "2023-02-12 16:16:32,321.321 DEBUG predict: Input Arg --> min_length\n",
      "2023-02-12 16:16:32,322.322 DEBUG predict: Input Value --> 0\n",
      "2023-02-12 16:16:32,323.323 DEBUG predict: Input Arg --> max_length\n",
      "2023-02-12 16:16:32,323.323 DEBUG predict: Input Value --> 150\n",
      "2023-02-12 16:16:32,324.324 DEBUG predict: START predict\n",
      "2023-02-12 16:16:32,330.330 DEBUG _new_conn: Starting new HTTPS connection (1): huggingface.co:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lancement get_image\n",
      "lancement de test_import\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-12 16:16:32,689.689 DEBUG _make_request: https://huggingface.co:443 \"GET /datasets/huggingface/documentation-images/resolve/main/coco_sample.png HTTP/1.1\" 302 1046\n",
      "2023-02-12 16:16:32,697.697 DEBUG _new_conn: Starting new HTTPS connection (1): cdn-lfs.huggingface.co:443\n",
      "2023-02-12 16:16:32,783.783 DEBUG _make_request: https://cdn-lfs.huggingface.co:443 \"GET /datasets/huggingface/documentation-images/cf6f3c4befa148732c7453e0de5afab00f682427435fead2d88b07a9615cdac2?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27coco_sample.png%3B+filename%3D%22coco_sample.png%22%3B&Expires=1676474077&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL2RhdGFzZXRzL2h1Z2dpbmdmYWNlL2RvY3VtZW50YXRpb24taW1hZ2VzL2NmNmYzYzRiZWZhMTQ4NzMyYzc0NTNlMGRlNWFmYWIwMGY2ODI0Mjc0MzVmZWFkMmQ4OGIwN2E5NjE1Y2RhYzI~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNjc2NDc0MDc3fX19XX0_&Signature=b0QzT7KEB6R-qmjqAL8Vq6qT1S2K4lAwV~wjoT9yuuNl8Ms80flFwKyK0u-mfpWONV7ZBCWgDsE9B6rx1WfMP61zYF9hW4h8WzFueMkeDt~MUujgzB756e2vcjveLds1JGDNsrv0ZL1jhUO48jFGhKX6C0O7X-qRQjuyanTPjGBzQg7p~zdDkQhSub0w-05N9aNFC7smNxQ2g9nm~I9MPHvkpHLFfS93LxdS4O90jyWCU5vsh9p6KBHV4dhK41l2T64iDKSkqsO8uy~VIfR~7mlPiVMT3k-cE55GMFbkWhDN95pRqvlD9YXLMy4e-RzVefoC7h0DJuoEJEwihPzewQ__&Key-Pair-Id=KVTP0A1DKRTAX HTTP/1.1\" 200 694498\n",
      "2023-02-12 16:16:32,839.839 DEBUG call: STREAM b'IHDR' 16 13\n",
      "2023-02-12 16:16:32,840.840 DEBUG call: STREAM b'IDAT' 41 65536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9374414682388306, 'label': 'Egyptian cat'},\n",
       " {'score': 0.03844257444143295, 'label': 'tabby, tabby cat'},\n",
       " {'score': 0.014411373995244503, 'label': 'tiger cat'},\n",
       " {'score': 0.0032743189949542284, 'label': 'lynx, catamount'},\n",
       " {'score': 0.0006795917288400233, 'label': 'Siamese cat, Siamese'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(input_type = \"image\",\n",
    "                    data = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c4d645e-059b-45db-b537-655431c349e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-12 16:16:37,014.014 DEBUG predict: Default arg --> min_length\n",
      "2023-02-12 16:16:37,016.016 DEBUG predict: Default Value --> 0\n",
      "2023-02-12 16:16:37,017.017 DEBUG predict: Default arg --> max_length\n",
      "2023-02-12 16:16:37,018.018 DEBUG predict: Default Value --> 150\n",
      "2023-02-12 16:16:37,020.020 DEBUG predict: Input Arg --> sentiment_model\n",
      "2023-02-12 16:16:37,021.021 DEBUG predict: Input Value --> <transformers.pipelines.text_classification.TextClassificationPipeline object at 0x7f612b335040>\n",
      "2023-02-12 16:16:37,022.022 DEBUG predict: Input Arg --> summarization_model\n",
      "2023-02-12 16:16:37,023.023 DEBUG predict: Input Value --> <transformers.pipelines.text2text_generation.SummarizationPipeline object at 0x7f6128f01100>\n",
      "2023-02-12 16:16:37,024.024 DEBUG predict: Input Arg --> translation_model\n",
      "2023-02-12 16:16:37,025.025 DEBUG predict: Input Value --> <transformers.pipelines.text2text_generation.TranslationPipeline object at 0x7f611b63a310>\n",
      "2023-02-12 16:16:37,026.026 DEBUG predict: Input Arg --> image_classification\n",
      "2023-02-12 16:16:37,027.027 DEBUG predict: Input Value --> <transformers.pipelines.image_classification.ImageClassificationPipeline object at 0x7f6254128880>\n",
      "2023-02-12 16:16:37,028.028 DEBUG predict: Input Arg --> input_type\n",
      "2023-02-12 16:16:37,029.029 DEBUG predict: Input Value --> sentiment\n",
      "2023-02-12 16:16:37,029.029 DEBUG predict: Input Arg --> data\n",
      "2023-02-12 16:16:37,030.030 DEBUG predict: Input Value --> That's great !\n",
      "2023-02-12 16:16:37,031.031 DEBUG predict: Input Arg --> min_length\n",
      "2023-02-12 16:16:37,031.031 DEBUG predict: Input Value --> 0\n",
      "2023-02-12 16:16:37,032.032 DEBUG predict: Input Arg --> max_length\n",
      "2023-02-12 16:16:37,033.033 DEBUG predict: Input Value --> 150\n",
      "2023-02-12 16:16:37,033.033 DEBUG predict: START predict\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998632669448853}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(input_type = \"sentiment\",\n",
    "                    data = \"That's great !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "213d7064-acf5-41c3-9ae0-c300e9f6a3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-12 16:16:39,953.953 DEBUG predict: Default arg --> min_length\n",
      "2023-02-12 16:16:39,955.955 DEBUG predict: Default Value --> 0\n",
      "2023-02-12 16:16:39,956.956 DEBUG predict: Default arg --> max_length\n",
      "2023-02-12 16:16:39,957.957 DEBUG predict: Default Value --> 150\n",
      "2023-02-12 16:16:39,958.958 DEBUG predict: Input Arg --> sentiment_model\n",
      "2023-02-12 16:16:39,959.959 DEBUG predict: Input Value --> <transformers.pipelines.text_classification.TextClassificationPipeline object at 0x7f612b335040>\n",
      "2023-02-12 16:16:39,960.960 DEBUG predict: Input Arg --> summarization_model\n",
      "2023-02-12 16:16:39,961.961 DEBUG predict: Input Value --> <transformers.pipelines.text2text_generation.SummarizationPipeline object at 0x7f6128f01100>\n",
      "2023-02-12 16:16:39,962.962 DEBUG predict: Input Arg --> translation_model\n",
      "2023-02-12 16:16:39,964.964 DEBUG predict: Input Value --> <transformers.pipelines.text2text_generation.TranslationPipeline object at 0x7f611b63a310>\n",
      "2023-02-12 16:16:39,965.965 DEBUG predict: Input Arg --> image_classification\n",
      "2023-02-12 16:16:39,966.966 DEBUG predict: Input Value --> <transformers.pipelines.image_classification.ImageClassificationPipeline object at 0x7f6254128880>\n",
      "2023-02-12 16:16:39,967.967 DEBUG predict: Input Arg --> input_type\n",
      "2023-02-12 16:16:39,968.968 DEBUG predict: Input Value --> translation\n",
      "2023-02-12 16:16:39,968.968 DEBUG predict: Input Arg --> data\n",
      "2023-02-12 16:16:39,969.969 DEBUG predict: Input Value --> An apple a day, keeps the doctor away\n",
      "2023-02-12 16:16:39,970.970 DEBUG predict: Input Arg --> min_length\n",
      "2023-02-12 16:16:39,971.971 DEBUG predict: Input Value --> 0\n",
      "2023-02-12 16:16:39,971.971 DEBUG predict: Input Arg --> max_length\n",
      "2023-02-12 16:16:39,972.972 DEBUG predict: Input Value --> 150\n",
      "2023-02-12 16:16:39,973.973 DEBUG predict: START predict\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'Une pomme par jour, éloigne le médecin'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(input_type = \"translation\",\n",
    "                    data = \"An apple a day, keeps the doctor away\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77191f1d-d649-4693-89cf-fe4da20a7218",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-12 16:16:42,703.703 DEBUG predict: Input Arg --> sentiment_model\n",
      "2023-02-12 16:16:42,705.705 DEBUG predict: Input Value --> <transformers.pipelines.text_classification.TextClassificationPipeline object at 0x7f612b335040>\n",
      "2023-02-12 16:16:42,706.706 DEBUG predict: Input Arg --> summarization_model\n",
      "2023-02-12 16:16:42,707.707 DEBUG predict: Input Value --> <transformers.pipelines.text2text_generation.SummarizationPipeline object at 0x7f6128f01100>\n",
      "2023-02-12 16:16:42,708.708 DEBUG predict: Input Arg --> translation_model\n",
      "2023-02-12 16:16:42,709.709 DEBUG predict: Input Value --> <transformers.pipelines.text2text_generation.TranslationPipeline object at 0x7f611b63a310>\n",
      "2023-02-12 16:16:42,711.711 DEBUG predict: Input Arg --> image_classification\n",
      "2023-02-12 16:16:42,711.711 DEBUG predict: Input Value --> <transformers.pipelines.image_classification.ImageClassificationPipeline object at 0x7f6254128880>\n",
      "2023-02-12 16:16:42,712.712 DEBUG predict: Input Arg --> input_type\n",
      "2023-02-12 16:16:42,713.713 DEBUG predict: Input Value --> summarization\n",
      "2023-02-12 16:16:42,714.714 DEBUG predict: Input Arg --> data\n",
      "2023-02-12 16:16:42,715.715 DEBUG predict: Input Value --> A Bear roaming the woods in search of berries happened on a fallen tree in which a swarm of Bees had stored their honey. The Bear began to nose around the log very carefully to find out if the Bees were at home. \n",
      "                        Just then one of the swarm came home from the clover field with a load of sweets. Guessing what the Bear was after, the Bee flew at him, stung him sharply and then disappeared into the hollow log. \n",
      "                        The Bear lost his temper in an instant, and sprang upon the log tooth and claw, to destroy the nest. But this only brought out the whole swarm. The poor Bear had to take to his heels, and he was able to save himself only by diving into a pool of water.\n",
      "2023-02-12 16:16:42,716.716 DEBUG predict: Input Arg --> min_length\n",
      "2023-02-12 16:16:42,716.716 DEBUG predict: Input Value --> 2\n",
      "2023-02-12 16:16:42,717.717 DEBUG predict: Input Arg --> max_length\n",
      "2023-02-12 16:16:42,718.718 DEBUG predict: Input Value --> 5\n",
      "2023-02-12 16:16:42,718.718 DEBUG predict: START predict\n",
      "Ignoring args : (2, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'summary_text': ' A Bear roaming the woods in search of berries happened on a fallen tree in which a swarm of Bees had stored their honey . The Bear lost his temper in an instant, and sprang upon the log tooth and claw, to destroy the nest . But this only brought out the whole swarm, and the Bear had to take to his heels .',\n",
       " 'input_text': 'A Bear roaming the woods in search of berries happened on a fallen tree in which a swarm of Bees had stored their honey. The Bear began to nose around the log very carefully to find out if the Bees were at home. \\n                        Just then one of the swarm came home from the clover field with a load of sweets. Guessing what the Bear was after, the Bee flew at him, stung him sharply and then disappeared into the hollow log. \\n                        The Bear lost his temper in an instant, and sprang upon the log tooth and claw, to destroy the nest. But this only brought out the whole swarm. The poor Bear had to take to his heels, and he was able to save himself only by diving into a pool of water.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_summarize = \"\"\"A Bear roaming the woods in search of berries happened on a fallen tree in which a swarm of Bees had stored their honey. The Bear began to nose around the log very carefully to find out if the Bees were at home. \n",
    "                        Just then one of the swarm came home from the clover field with a load of sweets. Guessing what the Bear was after, the Bee flew at him, stung him sharply and then disappeared into the hollow log. \n",
    "                        The Bear lost his temper in an instant, and sprang upon the log tooth and claw, to destroy the nest. But this only brought out the whole swarm. The poor Bear had to take to his heels, and he was able to save himself only by diving into a pool of water.\"\"\"\n",
    "\n",
    "loaded_model.predict(input_type = \"summarization\",\n",
    "                    data = text_to_summarize,\n",
    "                    min_length =  2, \n",
    "                     max_length = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "068f560b-5adb-41bc-bd9c-4897cc29d1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-12 16:16:47,717.717 DEBUG predict: Default arg --> data\n",
      "2023-02-12 16:16:47,719.719 DEBUG predict: Default Value --> None\n",
      "2023-02-12 16:16:47,721.721 DEBUG predict: Input Arg --> sentiment_model\n",
      "2023-02-12 16:16:47,722.722 DEBUG predict: Input Value --> <transformers.pipelines.text_classification.TextClassificationPipeline object at 0x7f612b335040>\n",
      "2023-02-12 16:16:47,724.724 DEBUG predict: Input Arg --> summarization_model\n",
      "2023-02-12 16:16:47,725.725 DEBUG predict: Input Value --> <transformers.pipelines.text2text_generation.SummarizationPipeline object at 0x7f6128f01100>\n",
      "2023-02-12 16:16:47,726.726 DEBUG predict: Input Arg --> translation_model\n",
      "2023-02-12 16:16:47,727.727 DEBUG predict: Input Value --> <transformers.pipelines.text2text_generation.TranslationPipeline object at 0x7f611b63a310>\n",
      "2023-02-12 16:16:47,728.728 DEBUG predict: Input Arg --> image_classification\n",
      "2023-02-12 16:16:47,729.729 DEBUG predict: Input Value --> <transformers.pipelines.image_classification.ImageClassificationPipeline object at 0x7f6254128880>\n",
      "2023-02-12 16:16:47,730.730 DEBUG predict: Input Arg --> input_type\n",
      "2023-02-12 16:16:47,730.730 DEBUG predict: Input Value --> summarization\n",
      "2023-02-12 16:16:47,731.731 DEBUG predict: Input Arg --> data\n",
      "2023-02-12 16:16:47,732.732 DEBUG predict: Input Value --> None\n",
      "2023-02-12 16:16:47,733.733 DEBUG predict: Input Arg --> min_length\n",
      "2023-02-12 16:16:47,734.734 DEBUG predict: Input Value --> 10\n",
      "2023-02-12 16:16:47,735.735 DEBUG predict: Input Arg --> max_length\n",
      "2023-02-12 16:16:47,735.735 DEBUG predict: Input Value --> 20\n",
      "2023-02-12 16:16:47,736.736 DEBUG predict: START predict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lancement download_story\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring args : (10, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'summary_text': ' A man who lived a long time ago believed that he could read the future in the stars . He called himself an Astrologer, and spent his time at night gazing at the sky . He thought he saw there that the end of the world was at hand, when all at once, down he went into a hole full of mud and water .',\n",
       " 'input_text': 'A man who lived a long time ago believed that he could read the future in the stars. He called himself an Astrologer, and spent his time at night gazing at the sky. One evening he was walking along the open road outside the village. His eyes were fixed on the stars. He thought he saw there that the end of the world was at hand, when all at once, down he went into a hole full of mud and water. There he stood up to his ears, in the muddy water, and madly clawing at the slippery sides of the hole in his effort to climb out. His cries for help soon brought the villagers running. As they pulled him out of the mud, one of them said: \"You pretend to read the future in the stars, and yet you fail to see what is at your feet! This may teach you to pay more attention to what is right in front of you, and let the future take care of itself.\" \"What use is it,\" said another, \"to read the stars, when you can\\'t see what\\'s right here on the earth?\"'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(input_type =  \"summarization\",\n",
    "                    min_length = 10, \n",
    "                    max_length = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ee9985-28cc-46e8-b745-b03107237a88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e9f815-f0c5-4e72-a10f-5942ab45df56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
